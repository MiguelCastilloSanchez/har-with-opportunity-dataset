{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424562c7-e286-4de8-9ab1-10a09a3989be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías para la carga, análisis y preprocesamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa66febe-6baf-4334-81c4-d0c52267ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los datos de entrenamiento y prueba\n",
    "subject_1 = ['OpportunityUCIDataset/dataset/S1-ADL1.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S1-ADL2.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S1-ADL3.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S1-Drill.dat']\n",
    "subject_2 = ['OpportunityUCIDataset/dataset/S2-ADL1.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S2-ADL2.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S2-ADL3.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S2-Drill.dat']\n",
    "subject_3 = ['OpportunityUCIDataset/dataset/S3-ADL1.dat',\n",
    "                'OpportunityUCIDataset/dataset/S3-ADL2.dat',\n",
    "                'OpportunityUCIDataset/dataset/S3-ADL3.dat',\n",
    "                'OpportunityUCIDataset/dataset/S3-Drill.dat']\n",
    "subject_4 = ['OpportunityUCIDataset/dataset/S4-ADL1.dat',\n",
    "                'OpportunityUCIDataset/dataset/S4-ADL2.dat',\n",
    "                'OpportunityUCIDataset/dataset/S4-ADL3.dat',\n",
    "                'OpportunityUCIDataset/dataset/S4-Drill.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69e82085-98c8-4be1-8229-d0388d37a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer columnas del dataset que se ecuentran en otro archivo\n",
    "col_names = []\n",
    "with open('col_names.txt','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        col_names.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "804c2e58-0731-42c7-b396-e049334f92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpportunityUCIDataset/dataset/S1-ADL1.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S1-ADL2.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S1-ADL3.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S1-Drill.dat se está leyendo...\n",
      "Lectura hecha!\n",
      "OpportunityUCIDataset/dataset/S2-ADL1.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S2-ADL2.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S2-ADL3.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S2-Drill.dat se está leyendo...\n",
      "Lectura hecha!\n",
      "OpportunityUCIDataset/dataset/S3-ADL1.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S3-ADL2.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S3-ADL3.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S3-Drill.dat se está leyendo...\n",
      "Lectura hecha!\n",
      "OpportunityUCIDataset/dataset/S4-ADL1.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S4-ADL2.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S4-ADL3.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S4-Drill.dat se está leyendo...\n",
      "Lectura hecha!\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "df_subject_1 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_1):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_1 = df_subject_1._append(file_data, ignore_index=True)\n",
    "df_subject_1.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n",
    "############################################################\n",
    "df_subject_2 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_2):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_2= df_subject_2._append(file_data, ignore_index=True)\n",
    "df_subject_2.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n",
    "############################################################\n",
    "df_subject_3 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_3):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_3 = df_subject_3._append(file_data, ignore_index=True)\n",
    "df_subject_3.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n",
    "############################################################\n",
    "df_subject_4 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_4):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_4 = df_subject_4._append(file_data, ignore_index=True)\n",
    "df_subject_4.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc832a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cde3ec1a-0735-420a-8ad3-b59ee5f1631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_to_simple_activities(df):\n",
    "    # Segmentación de la base de datos a solo las simples (Parado, caminando, sentado, acostado)\n",
    "    df = df.drop(['HL_Activity','LL_Left_Arm','LL_Left_Arm_Object','LL_Right_Arm',\n",
    "                  'LL_Right_Arm_Object', 'ML_Both_Arms'], axis = 1)\n",
    "    # Se eliminan los ejemplos que no entran en alguna de las 4 actividades\n",
    "    df = df[df['Locomotion'] != 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cf28db7-2200-4534-92e8-53059e1c2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_new_labels(df):\n",
    "    # Se mapean los nuevos labels\n",
    "    mapping = {1:0, 2:1, 4:2, 5:3}\n",
    "    df['Locomotion'] = df['Locomotion'].map(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0de847c6-1fed-4fb6-905c-ff2a798db495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_no_body_sensors(df):\n",
    "    df_labels = df['Locomotion']\n",
    "    df = df.drop(df.iloc[:,134:243], axis=1)\n",
    "    \n",
    "    three_axis_columns = [col for col in df.columns if 'X' in col or 'Y' in col or 'Z' in col]\n",
    "    df = df[three_axis_columns]\n",
    "    df = df.assign(label=df_labels)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcbbbbb8-f48d-446a-b484-a7360311590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    # Manejo de valores nulos por medio de imputación hacia delante\n",
    "    limit = df.shape[1]*0.9\n",
    "    df = df.dropna(axis='rows',thresh = limit)\n",
    "    df.iloc[0] = df.iloc[0].fillna(0)\n",
    "    df = df.ffill()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f403c2-1d56-4cd3-a7f0-b0f92ec6ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df):\n",
    "    window_size = 90\n",
    "    total_sensors = int(df.shape[1]/3)\n",
    "    total_samples = df.shape[0]//window_size\n",
    "    \n",
    "    first_column_from_sensor = 0\n",
    "    \n",
    "    resultados_caracteristicas = {\n",
    "        'mode label': [],\n",
    "    }\n",
    "    \n",
    "    for i in range(total_sensors):\n",
    "        start_rows = 0\n",
    "        end_rows = window_size\n",
    "            \n",
    "        for j in range(total_samples):\n",
    "            col_x = df.iloc[start_rows:end_rows, first_column_from_sensor]\n",
    "            col_y = df.iloc[start_rows:end_rows, first_column_from_sensor+1]\n",
    "            col_z = df.iloc[start_rows:end_rows, first_column_from_sensor+2]\n",
    "\n",
    "            # Estadísticos juntando los 3 ejes\n",
    "            magnitud = np.sqrt(col_x**2 + col_y**2 + col_z**2)\n",
    "            media_magnitud = np.mean(magnitud)\n",
    "            std_magnitud = np.std(magnitud)\n",
    "            auc_magnitud = np.sum(magnitud)\n",
    "\n",
    "            # Estadísticos de cada eje\n",
    "            mean_axis_x = col_x.mean()\n",
    "            std_axis_x = col_x.std()\n",
    "            max_axis_x = col_x.max()\n",
    "\n",
    "            mean_axis_y = col_y.mean()\n",
    "            std_axis_y = col_y.std()\n",
    "            max_axis_y = col_y.max()\n",
    "\n",
    "            mean_axis_z = col_z.mean()\n",
    "            std_axis_z = col_z.std()\n",
    "            max_axis_z = col_z.max()\n",
    "\n",
    "            # Nombre de cada sensor\n",
    "            sensor_name = df.columns[first_column_from_sensor][:-1]\n",
    "\n",
    "            # Nombres estadísticos eje X\n",
    "            mean_axis_x_name = 'mean ' + df.columns[first_column_from_sensor]\n",
    "            std_axis_x_name = 'std ' + df.columns[first_column_from_sensor]\n",
    "            max_axis_x_name = 'max ' + df.columns[first_column_from_sensor]\n",
    "\n",
    "            # Nombres estadísticos eje Y\n",
    "            mean_axis_y_name = 'mean ' + df.columns[first_column_from_sensor+1]\n",
    "            std_axis_y_name = 'std ' + df.columns[first_column_from_sensor+1]\n",
    "            max_axis_y_name = 'max ' + df.columns[first_column_from_sensor+1]\n",
    "\n",
    "            # Nombres estadísticos eje Z\n",
    "            mean_axis_z_name = 'mean ' + df.columns[first_column_from_sensor+2]\n",
    "            std_axis_z_name = 'std ' + df.columns[first_column_from_sensor+2]\n",
    "            max_axis_z_name = 'max ' + df.columns[first_column_from_sensor+2]\n",
    "            \n",
    "            # Nombres estadísticos de los 3 ejes \n",
    "            mean_magnitude_name = 'MM ' + sensor_name\n",
    "            std_magnitude_name = 'StdM ' + sensor_name\n",
    "            AUC_magnitude_name = 'AUCM ' + sensor_name\n",
    "\n",
    "\n",
    "            if mean_magnitude_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_magnitude_name] = []\n",
    "            if std_magnitude_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_magnitude_name] = []\n",
    "            if AUC_magnitude_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[AUC_magnitude_name] = []\n",
    "            if mean_axis_x_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_axis_x_name] = []\n",
    "            if std_axis_x_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_axis_x_name] = []\n",
    "            if max_axis_x_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[max_axis_x_name] = []\n",
    "            if mean_axis_y_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_axis_y_name] = []\n",
    "            if std_axis_y_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_axis_y_name] = []\n",
    "            if max_axis_y_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[max_axis_y_name] = []\n",
    "            if mean_axis_z_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_axis_z_name] = []\n",
    "            if std_axis_z_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_axis_z_name] = []\n",
    "            if max_axis_z_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[max_axis_z_name] = []\n",
    "    \n",
    "            resultados_caracteristicas[mean_magnitude_name].append(media_magnitud)\n",
    "            resultados_caracteristicas[std_magnitude_name].append(std_magnitud)\n",
    "            resultados_caracteristicas[AUC_magnitude_name].append(auc_magnitud)\n",
    "            resultados_caracteristicas[mean_axis_x_name].append(mean_axis_x)\n",
    "            resultados_caracteristicas[std_axis_x_name].append(std_axis_x)\n",
    "            resultados_caracteristicas[max_axis_x_name].append(max_axis_x)\n",
    "            resultados_caracteristicas[mean_axis_y_name].append(mean_axis_y)\n",
    "            resultados_caracteristicas[std_axis_y_name].append(std_axis_y)\n",
    "            resultados_caracteristicas[max_axis_y_name].append(max_axis_y)\n",
    "            resultados_caracteristicas[mean_axis_z_name].append(mean_axis_z)\n",
    "            resultados_caracteristicas[std_axis_z_name].append(std_axis_z)\n",
    "            resultados_caracteristicas[max_axis_z_name].append(max_axis_z)\n",
    "            \n",
    "            start_rows = end_rows\n",
    "            end_rows += 90\n",
    "        \n",
    "        first_column_from_sensor += 3\n",
    "        \n",
    "    start_rows = 0\n",
    "    end_rows = window_size\n",
    "    for k in range(total_samples):\n",
    "        mode = df.iloc[start_rows:end_rows, 111].mode()[0]\n",
    "        resultados_caracteristicas['mode label'].append(mode)\n",
    "        \n",
    "        start_rows = end_rows\n",
    "        end_rows += 90\n",
    "    \n",
    "    df = pd.DataFrame(resultados_caracteristicas)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "560d1962-5da3-48bc-acb1-6e8e9b9e2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_training_data(df_training):\n",
    "    \n",
    "    labels = df_training.iloc[:, 0]\n",
    "    data = df_training.iloc[:, 1:]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    scaled_df_training = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    scaled_df_training.insert(0, df_training.columns[0], labels)\n",
    "\n",
    "    return scaled_df_training, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bfb05a55-f730-49f2-825f-49d5a31b2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_test_data(df, scaler):\n",
    "    labels = df.iloc[:, 0]\n",
    "    data = df.iloc[:, 1:]\n",
    "    \n",
    "    scaled_data = scaler.transform(data)\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    scaled_df.insert(0, df.columns[0], labels)\n",
    "\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3497a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features(df):\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "    X = df.iloc[:, 1:]  \n",
    "    y = df.iloc[:, 0]   \n",
    "\n",
    "    k_best_features = 300  \n",
    "    selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "\n",
    "    X_best = selector.fit_transform(X, y)\n",
    "\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    X_best = pd.DataFrame(X_best, columns=selected_columns)\n",
    "\n",
    "    X_best.insert(0, df.columns[0], y)\n",
    "\n",
    "    return X_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "911ee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features_test(df_training, df_test):\n",
    "    columns_training = df_training.columns.tolist()\n",
    "    for column in df_test.columns:\n",
    "        if column not in columns_training:\n",
    "            df_test = df_test.drop(column, axis = 1)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "402a5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_using_lda(df):\n",
    "    labels = df.iloc[:, 0]\n",
    "    features = df.iloc[:, 1:]\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "    features_lda = lda.fit_transform(features, labels)\n",
    "\n",
    "    print(\"Varianza explicada por cada componente:\", lda.explained_variance_ratio_)\n",
    "    \n",
    "    columns_lda = ['Component_1', 'Component_2', 'Component_3']\n",
    "    df_lda = pd.DataFrame(data=features_lda, columns=columns_lda)\n",
    "    df_lda['labels'] = labels\n",
    "    return df_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c13cba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_3d_chart(df):\n",
    "    %matplotlib notebook\n",
    "\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    colors = ['r', 'g', 'b', 'y', 'c', 'm']\n",
    "    unic_labels = df['labels'].unique()\n",
    "\n",
    "    for label, color in zip(unic_labels, colors):\n",
    "        index = df['labels'] == label\n",
    "        ax.scatter(df.loc[index, 'Component_1'],\n",
    "                   df.loc[index, 'Component_2'],\n",
    "                   df.loc[index, 'Component_3'],\n",
    "                   c=color,\n",
    "                   label=label,\n",
    "                   s=50,\n",
    "                   alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Component 1')\n",
    "    ax.set_ylabel('Component 2')\n",
    "    ax.set_zlabel('Component 3')\n",
    "    ax.set_title('3D Display with LDA')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0328671a-60e0-4d48-8f0e-50d92e43fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classes(df):\n",
    "    locomotion = pd.Series([0,0,0,0],index=['Stan', 'Walk', 'Sit', 'Lie'])\n",
    "    for value in df.loc[:,'labels']:\n",
    "        if 0 <= value <= 3:\n",
    "            if value == 0:\n",
    "                locomotion['Stan'] += 1\n",
    "            elif value == 1:\n",
    "                locomotion['Walk'] += 1\n",
    "            elif value == 2:\n",
    "                locomotion['Sit'] += 1\n",
    "            elif value == 3:\n",
    "                locomotion['Lie'] += 1\n",
    "    print(locomotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b2be31c-f111-462a-a69f-309c9816c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_training_and_test(df_training, df_test):\n",
    "    X_train = df_training.iloc[:, :3]  \n",
    "    y_train = df_training.iloc[:, 3]   \n",
    "\n",
    "    X_test = df_test.iloc[:, :3]  \n",
    "    y_test = df_test.iloc[:, 3]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "484d4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_subject_data(df):\n",
    "    df = segmentation_to_simple_activities(df)\n",
    "    df = mapping_new_labels(df)\n",
    "    df = cut_no_body_sensors(df)\n",
    "    df = handle_missing_values(df)\n",
    "    df = feature_extraction(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02c04ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_data(df_training_1, df_training_2, df_training_3):\n",
    "\n",
    "    df_training_1 = preprocess_subject_data(df_training_1)\n",
    "    df_training_2 = preprocess_subject_data(df_training_2)\n",
    "    df_training_3 = preprocess_subject_data(df_training_3)\n",
    "    \n",
    "    df_training = pd.concat([df_training_1, df_training_2, df_training_3], ignore_index=True)\n",
    "    df_training = select_best_features(df_training)\n",
    "    df_training, scaler = scale_training_data(df_training)\n",
    "    \n",
    "    df_training_before_lda = df_training\n",
    "    \n",
    "    df_training = transform_using_lda(df_training)\n",
    "    \n",
    "    return df_training, df_training_before_lda, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "029ca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(df_test, df_training_before_lda, scaler):\n",
    "    df_test = preprocess_subject_data(df_test)\n",
    "    df_test = select_best_features_test(df_training_before_lda, df_test)\n",
    "    df_test = scale_test_data(df_test, scaler)\n",
    "    df_test = transform_using_lda(df_test)\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a26a13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all_data(df_training_1, df_training_2, df_training_3, df_test):\n",
    "    df_training, df_training_before_lda, scaler = preprocess_training_data(df_training_1, df_training_2, df_training_3)\n",
    "    df_test = preprocess_test_data(df_test, df_training_before_lda, scaler)\n",
    "    \n",
    "    return df_training, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c19aefb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Varianza explicada por cada componente: [0.60286357 0.31560239 0.08153403]\n",
      "Varianza explicada por cada componente: [0.73912645 0.21218441 0.04868914]\n"
     ]
    }
   ],
   "source": [
    "df_training, df_test = preprocess_all_data(df_subject_1, df_subject_2, df_subject_3, df_subject_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99beca0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = divide_training_and_test(df_training, df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d24b2e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporte de Clasificación:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.95      0.96       667\n",
      "           1       0.90      0.97      0.93       282\n",
      "           2       0.99      0.95      0.97       196\n",
      "           3       1.00      0.97      0.99        35\n",
      "\n",
      "    accuracy                           0.96      1180\n",
      "   macro avg       0.97      0.96      0.96      1180\n",
      "weighted avg       0.96      0.96      0.96      1180\n",
      "\n",
      "Matriz de Confusión:\n",
      "      0    1    2   3\n",
      "0  636   31    0   0\n",
      "1    9  273    0   0\n",
      "2    8    1  187   0\n",
      "3    0    0    1  34\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "rf_classifier = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "print(\"Reporte de Clasificación:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=rf_classifier.classes_, columns=rf_classifier.classes_)\n",
    "print(\"Matriz de Confusión:\\n\", conf_matrix_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "79fa3f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9483050847457627\n",
      "Confusion Matrix:\n",
      "[[625  41   1   0]\n",
      " [ 18 264   0   0]\n",
      " [  0   1 195   0]\n",
      " [  0   0   0  35]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95       667\n",
      "           1       0.86      0.94      0.90       282\n",
      "           2       0.99      0.99      0.99       196\n",
      "           3       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           0.95      1180\n",
      "   macro avg       0.96      0.97      0.96      1180\n",
      "weighted avg       0.95      0.95      0.95      1180\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "perceptron_model = Perceptron(class_weight='balanced', max_iter=1000, eta0=0.1)\n",
    "perceptron_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = perceptron_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8dc8da9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.92      0.95       667\n",
      "           1       0.84      0.98      0.91       282\n",
      "           2       1.00      0.99      0.99       196\n",
      "           3       1.00      1.00      1.00        35\n",
      "\n",
      "    accuracy                           0.95      1180\n",
      "   macro avg       0.96      0.97      0.96      1180\n",
      "weighted avg       0.96      0.95      0.95      1180\n",
      "\n",
      "Precisión global del modelo: 0.9491525423728814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "logistic_reg = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "logistic_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logistic_reg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "accuracy = logistic_reg.score(X_test, y_test)\n",
    "print(\"Precisión global del modelo:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5294733d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
