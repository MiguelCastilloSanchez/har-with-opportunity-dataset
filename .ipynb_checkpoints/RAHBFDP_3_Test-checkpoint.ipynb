{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "424562c7-e286-4de8-9ab1-10a09a3989be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Librerías para la carga, análisis y preprocesamiento de datos\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa66febe-6baf-4334-81c4-d0c52267ea12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de los datos de entrenamiento y prueba\n",
    "subject_1 = ['OpportunityUCIDataset/dataset/S1-ADL1.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S1-ADL2.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S1-ADL3.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S1-Drill.dat']\n",
    "subject_2 = ['OpportunityUCIDataset/dataset/S2-ADL1.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S2-ADL2.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S2-ADL3.dat',\n",
    "                 'OpportunityUCIDataset/dataset/S2-Drill.dat']\n",
    "subject_3 = ['OpportunityUCIDataset/dataset/S3-ADL1.dat',\n",
    "                'OpportunityUCIDataset/dataset/S3-ADL2.dat',\n",
    "                'OpportunityUCIDataset/dataset/S3-ADL3.dat',\n",
    "                'OpportunityUCIDataset/dataset/S3-Drill.dat']\n",
    "subject_4 = ['OpportunityUCIDataset/dataset/S4-ADL1.dat',\n",
    "                'OpportunityUCIDataset/dataset/S4-ADL2.dat',\n",
    "                'OpportunityUCIDataset/dataset/S4-ADL3.dat',\n",
    "                'OpportunityUCIDataset/dataset/S4-Drill.dat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69e82085-98c8-4be1-8229-d0388d37a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leer columnas del dataset que se ecuentran en otro archivo\n",
    "col_names = []\n",
    "with open('col_names.txt','r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        col_names.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804c2e58-0731-42c7-b396-e049334f92f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpportunityUCIDataset/dataset/S1-ADL1.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S1-ADL2.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S1-ADL3.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S1-Drill.dat se está leyendo...\n",
      "Lectura hecha!\n",
      "OpportunityUCIDataset/dataset/S2-ADL1.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S2-ADL2.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S2-ADL3.dat se está leyendo...\n",
      "OpportunityUCIDataset/dataset/S2-Drill.dat se está leyendo...\n",
      "Lectura hecha!\n",
      "OpportunityUCIDataset/dataset/S3-ADL1.dat se está leyendo...\n"
     ]
    }
   ],
   "source": [
    "############################################################\n",
    "df_subject_1 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_1):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_1 = df_subject_1._append(file_data, ignore_index=True)\n",
    "df_subject_1.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n",
    "############################################################\n",
    "df_subject_2 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_2):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_2= df_subject_2._append(file_data, ignore_index=True)\n",
    "df_subject_2.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n",
    "############################################################\n",
    "df_subject_3 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_3):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_3 = df_subject_3._append(file_data, ignore_index=True)\n",
    "df_subject_3.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n",
    "############################################################\n",
    "df_subject_4 = pd.DataFrame()\n",
    "for i, file in enumerate(subject_4):\n",
    "    print(file,\"se está leyendo...\")\n",
    "    file_data = pd.read_table(file, header=None, sep='\\s+')\n",
    "    file_data.columns = col_names      \n",
    "    df_subject_4 = df_subject_4._append(file_data, ignore_index=True)\n",
    "df_subject_4.reset_index(drop=True, inplace=True)\n",
    "print(\"Lectura hecha!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3ec1a-0735-420a-8ad3-b59ee5f1631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation_to_simple_activities(df):\n",
    "    # Segmentación de la base de datos a solo las simples (Parado, caminando, sentado, acostado)\n",
    "    df = df.drop(['HL_Activity','LL_Left_Arm','LL_Left_Arm_Object','LL_Right_Arm',\n",
    "                  'LL_Right_Arm_Object', 'ML_Both_Arms'], axis = 1)\n",
    "    # Se eliminan los ejemplos que no entran en alguna de las 4 actividades\n",
    "    df = df[df['Locomotion'] != 0]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf28db7-2200-4534-92e8-53059e1c2e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_new_labels(df):\n",
    "    # Se mapean los nuevos labels\n",
    "    mapping = {1:0, 2:1, 4:2, 5:3}\n",
    "    df['Locomotion'] = df['Locomotion'].map(mapping)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de847c6-1fed-4fb6-905c-ff2a798db495",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_no_body_sensors(df):\n",
    "    df_labels = df['Locomotion']\n",
    "    df = df.drop(df.iloc[:,134:243], axis=1)\n",
    "    \n",
    "    three_axis_columns = [col for col in df.columns if 'X' in col or 'Y' in col or 'Z' in col]\n",
    "    df = df[three_axis_columns]\n",
    "    df = df.assign(label=df_labels)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbbbb8-f48d-446a-b484-a7360311590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_missing_values(df):\n",
    "    # Manejo de valores nulos por medio de imputación hacia delante\n",
    "    limit = df.shape[1]*0.9\n",
    "    df = df.dropna(axis='rows',thresh = limit)\n",
    "    df.iloc[0] = df.iloc[0].fillna(0)\n",
    "    df = df.ffill()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f403c2-1d56-4cd3-a7f0-b0f92ec6ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(df):\n",
    "    window_size = 90\n",
    "    total_sensors = int(df.shape[1]/3)\n",
    "    total_samples = df.shape[0]//window_size\n",
    "    \n",
    "    first_column_from_sensor = 0\n",
    "    \n",
    "    resultados_caracteristicas = {\n",
    "        'mode label': [],\n",
    "    }\n",
    "    \n",
    "    for i in range(total_sensors):\n",
    "        start_rows = 0\n",
    "        end_rows = window_size\n",
    "            \n",
    "        for j in range(total_samples):\n",
    "            col_x = df.iloc[start_rows:end_rows, first_column_from_sensor]\n",
    "            col_y = df.iloc[start_rows:end_rows, first_column_from_sensor+1]\n",
    "            col_z = df.iloc[start_rows:end_rows, first_column_from_sensor+2]\n",
    "\n",
    "            # Estadísticos juntando los 3 ejes\n",
    "            magnitud = np.sqrt(col_x**2 + col_y**2 + col_z**2)\n",
    "            media_magnitud = np.mean(magnitud)\n",
    "            std_magnitud = np.std(magnitud)\n",
    "            auc_magnitud = np.sum(magnitud)\n",
    "\n",
    "            # Estadísticos de cada eje\n",
    "            mean_axis_x = col_x.mean()\n",
    "            std_axis_x = col_x.std()\n",
    "            max_axis_x = col_x.max()\n",
    "\n",
    "            mean_axis_y = col_y.mean()\n",
    "            std_axis_y = col_y.std()\n",
    "            max_axis_y = col_y.max()\n",
    "\n",
    "            mean_axis_z = col_z.mean()\n",
    "            std_axis_z = col_z.std()\n",
    "            max_axis_z = col_z.max()\n",
    "\n",
    "            # Nombre de cada sensor\n",
    "            sensor_name = df.columns[first_column_from_sensor][:-1]\n",
    "\n",
    "            # Nombres estadísticos eje X\n",
    "            mean_axis_x_name = 'mean ' + df.columns[first_column_from_sensor]\n",
    "            std_axis_x_name = 'std ' + df.columns[first_column_from_sensor]\n",
    "            max_axis_x_name = 'max ' + df.columns[first_column_from_sensor]\n",
    "\n",
    "            # Nombres estadísticos eje Y\n",
    "            mean_axis_y_name = 'mean ' + df.columns[first_column_from_sensor+1]\n",
    "            std_axis_y_name = 'std ' + df.columns[first_column_from_sensor+1]\n",
    "            max_axis_y_name = 'max ' + df.columns[first_column_from_sensor+1]\n",
    "\n",
    "            # Nombres estadísticos eje Z\n",
    "            mean_axis_z_name = 'mean ' + df.columns[first_column_from_sensor+2]\n",
    "            std_axis_z_name = 'std ' + df.columns[first_column_from_sensor+2]\n",
    "            max_axis_z_name = 'max ' + df.columns[first_column_from_sensor+2]\n",
    "            \n",
    "            # Nombres estadísticos de los 3 ejes \n",
    "            mean_magnitude_name = 'MM ' + sensor_name\n",
    "            std_magnitude_name = 'StdM ' + sensor_name\n",
    "            AUC_magnitude_name = 'AUCM ' + sensor_name\n",
    "\n",
    "\n",
    "            if mean_magnitude_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_magnitude_name] = []\n",
    "            if std_magnitude_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_magnitude_name] = []\n",
    "            if AUC_magnitude_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[AUC_magnitude_name] = []\n",
    "            if mean_axis_x_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_axis_x_name] = []\n",
    "            if std_axis_x_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_axis_x_name] = []\n",
    "            if max_axis_x_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[max_axis_x_name] = []\n",
    "            if mean_axis_y_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_axis_y_name] = []\n",
    "            if std_axis_y_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_axis_y_name] = []\n",
    "            if max_axis_y_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[max_axis_y_name] = []\n",
    "            if mean_axis_z_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[mean_axis_z_name] = []\n",
    "            if std_axis_z_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[std_axis_z_name] = []\n",
    "            if max_axis_z_name not in resultados_caracteristicas:\n",
    "                resultados_caracteristicas[max_axis_z_name] = []\n",
    "    \n",
    "            resultados_caracteristicas[mean_magnitude_name].append(media_magnitud)\n",
    "            resultados_caracteristicas[std_magnitude_name].append(std_magnitud)\n",
    "            resultados_caracteristicas[AUC_magnitude_name].append(auc_magnitud)\n",
    "            resultados_caracteristicas[mean_axis_x_name].append(mean_axis_x)\n",
    "            resultados_caracteristicas[std_axis_x_name].append(std_axis_x)\n",
    "            resultados_caracteristicas[max_axis_x_name].append(max_axis_x)\n",
    "            resultados_caracteristicas[mean_axis_y_name].append(mean_axis_y)\n",
    "            resultados_caracteristicas[std_axis_y_name].append(std_axis_y)\n",
    "            resultados_caracteristicas[max_axis_y_name].append(max_axis_y)\n",
    "            resultados_caracteristicas[mean_axis_z_name].append(mean_axis_z)\n",
    "            resultados_caracteristicas[std_axis_z_name].append(std_axis_z)\n",
    "            resultados_caracteristicas[max_axis_z_name].append(max_axis_z)\n",
    "            \n",
    "            start_rows = end_rows\n",
    "            end_rows += 90\n",
    "        \n",
    "        first_column_from_sensor += 3\n",
    "        \n",
    "    start_rows = 0\n",
    "    end_rows = window_size\n",
    "    for k in range(total_samples):\n",
    "        mode = df.iloc[start_rows:end_rows, 111].mode()[0]\n",
    "        resultados_caracteristicas['mode label'].append(mode)\n",
    "        \n",
    "        start_rows = end_rows\n",
    "        end_rows += 90\n",
    "    \n",
    "    df = pd.DataFrame(resultados_caracteristicas)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d1962-5da3-48bc-acb1-6e8e9b9e2455",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_training_data(df_train):\n",
    "    \n",
    "    labels = df_train.iloc[:, 0]\n",
    "    data = df_train.iloc[:, 1:]\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "    scaled_df_train = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    scaled_df_train.insert(0, df_train.columns[0], labels)\n",
    "\n",
    "    return scaled_df_train, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb05a55-f730-49f2-825f-49d5a31b2de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_test_data(df, scaler):\n",
    "    labels = df.iloc[:, 0]\n",
    "    data = df.iloc[:, 1:]\n",
    "    \n",
    "    scaled_data = scaler.transform(data)\n",
    "    \n",
    "    scaled_df = pd.DataFrame(scaled_data, columns=data.columns)\n",
    "    scaled_df.insert(0, df.columns[0], labels)\n",
    "\n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3497a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features(df):\n",
    "    from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "    X = df.iloc[:, 1:]  \n",
    "    y = df.iloc[:, 0]   \n",
    "\n",
    "    k_best_features = 300  \n",
    "    selector = SelectKBest(score_func=f_classif, k=k_best_features)\n",
    "\n",
    "    X_best = selector.fit_transform(X, y)\n",
    "\n",
    "    selected_columns = X.columns[selector.get_support()]\n",
    "    X_best = pd.DataFrame(X_best, columns=selected_columns)\n",
    "\n",
    "    X_best.insert(0, df.columns[0], y)\n",
    "\n",
    "    return X_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ee992",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_best_features_test(df_train, df_test):\n",
    "    columns_training = df_train.columns.tolist()\n",
    "    for column in df_test.columns:\n",
    "        if column not in columns_training:\n",
    "            df_test = df_test.drop(column, axis = 1)\n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402a5a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_using_lda(df):\n",
    "    labels = df.iloc[:, 0]\n",
    "    features = df.iloc[:, 1:]\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=3)\n",
    "    features_lda = lda.fit_transform(features, labels)\n",
    "\n",
    "    print(\"Varianza explicada por cada componente:\", lda.explained_variance_ratio_)\n",
    "    \n",
    "    columns_lda = ['Component_1', 'Component_2', 'Component_3']\n",
    "    df_lda = pd.DataFrame(data=features_lda, columns=columns_lda)\n",
    "    df_lda['labels'] = labels\n",
    "    return df_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13cba40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_3d_chart(df):\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    colors = ['r', 'g', 'b', 'y', 'c', 'm']\n",
    "    unic_labels = df['labels'].unique()\n",
    "\n",
    "    for label, color in zip(unic_labels, colors):\n",
    "        index = df['labels'] == label\n",
    "        ax.scatter(df.loc[index, 'Component_1'],\n",
    "                   df.loc[index, 'Component_2'],\n",
    "                   df.loc[index, 'Component_3'],\n",
    "                   c=color,\n",
    "                   label=label,\n",
    "                   s=50,\n",
    "                   alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Component 1')\n",
    "    ax.set_ylabel('Component 2')\n",
    "    ax.set_zlabel('Component 3')\n",
    "    ax.set_title('3D Display with LDA')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0328671a-60e0-4d48-8f0e-50d92e43fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classes(df):\n",
    "    locomotion = pd.Series([0,0,0,0],index=['Stan', 'Walk', 'Sit', 'Lie'])\n",
    "    for value in df.loc[:,'labels']:\n",
    "        if 0 <= value <= 3:\n",
    "            if value == 0:\n",
    "                locomotion['Stan'] += 1\n",
    "            elif value == 1:\n",
    "                locomotion['Walk'] += 1\n",
    "            elif value == 2:\n",
    "                locomotion['Sit'] += 1\n",
    "            elif value == 3:\n",
    "                locomotion['Lie'] += 1\n",
    "    print(locomotion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2be31c-f111-462a-a69f-309c9816c1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_training_and_test(df_train, df_test):\n",
    "    X_train = df_train.iloc[:, :3]  \n",
    "    y_train = df_train.iloc[:, 3]   \n",
    "\n",
    "    X_test = df_test.iloc[:, :3]  \n",
    "    y_test = df_test.iloc[:, 3]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484d4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_subject_data(df):\n",
    "    df = segmentation_to_simple_activities(df)\n",
    "    df = mapping_new_labels(df)\n",
    "    df = cut_no_body_sensors(df)\n",
    "    df = handle_missing_values(df)\n",
    "    df = feature_extraction(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c04ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_training_data(df_train_1, df_train_2, df_train_3):\n",
    "\n",
    "    df_train_1 = preprocess_subject_data(df_train_1)\n",
    "    df_train_2 = preprocess_subject_data(df_train_2)\n",
    "    df_train_3 = preprocess_subject_data(df_train_3)\n",
    "    \n",
    "    df_train = pd.concat([df_train_1, df_train_2, df_train_3], ignore_index=True)\n",
    "    df_train = select_best_features(df_train)\n",
    "    df_train, scaler = scale_training_data(df_train)\n",
    "    \n",
    "    df_train_before_lda = df_train\n",
    "    \n",
    "    df_train = transform_using_lda(df_train)\n",
    "    \n",
    "    return df_train, df_train_before_lda, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029ca75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_test_data(df_test, df_train_before_lda, scaler):\n",
    "    df_test = preprocess_subject_data(df_test)\n",
    "    df_test = select_best_features_test(df_train_before_lda, df_test)\n",
    "    df_test = scale_test_data(df_test, scaler)\n",
    "    df_test = transform_using_lda(df_test)\n",
    "    \n",
    "    return df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a13ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_all_data(df_train_1, df_train_2, df_train_3, df_test):\n",
    "    df_train, df_train_before_lda, scaler = preprocess_training_data(df_train_1, df_train_2, df_train_3)\n",
    "    df_test = preprocess_test_data(df_test, df_train_before_lda, scaler)\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41dda07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "total_combinations = [\n",
    "[df_subject_1, df_subject_2, df_subject_3, df_subject_4],\n",
    "[df_subject_1, df_subject_2, df_subject_4, df_subject_3],\n",
    "[df_subject_1, df_subject_3, df_subject_4, df_subject_2],\n",
    "[df_subject_2, df_subject_3, df_subject_4, df_subject_1]\n",
    "]\n",
    "\n",
    "classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(class_weight='balanced'),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced'),\n",
    "    \"Perceptron\": Perceptron(class_weight='balanced')\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"Accuracy\": accuracy_score,\n",
    "    \"Precision\": precision_score,\n",
    "    \"Recall\": recall_score,\n",
    "    \"F1-score\": f1_score\n",
    "}\n",
    "\n",
    "cross_validation_results = {\n",
    "    'Accuracy': [],\n",
    "    'Precision': [],\n",
    "    'Recall': [],\n",
    "    'F1-score': []\n",
    "}\n",
    "\n",
    "def train_and_evaluate(classifier, X_train, y_train, X_test, y_test):\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = classifier.predict(X_test)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "for combination in total_combinations:\n",
    "    print(\"Procesando combinación...\")\n",
    "    df_train, df_test = preprocess_all_data(*combination)\n",
    "    X_train, y_train, X_test, y_test = divide_training_and_test(df_train, df_test)\n",
    "    for clf_name, clf in classifiers.items():\n",
    "        accuracy, precision, recall, f1 = train_and_evaluate(clf, X_train, y_train, X_test, y_test)\n",
    "\n",
    "        cross_validation_results['Accuracy'].append(accuracy)\n",
    "        cross_validation_results['Precision'].append(precision)\n",
    "        cross_validation_results['Recall'].append(recall)\n",
    "        cross_validation_results['F1-score'].append(f1)\n",
    "        \n",
    "\n",
    "df_cross_validation_results = pd.DataFrame(cross_validation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303bf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
